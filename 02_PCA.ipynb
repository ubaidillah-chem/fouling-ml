{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ubaidillah-chem/fouling-ml/blob/main/02_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YocQBJvR-5Pw"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "R3EFnNNMAU8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the re-uploaded dataset\n",
        "df = pd.read_csv(\"gdrive/MyDrive/dataset.csv\")\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(columns=['Rf'])\n",
        "y = df['Rf']\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA to retain 95% of the variance\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Create a DataFrame with PCA results\n",
        "pca_columns = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
        "df_pca = pd.DataFrame(X_pca, columns=pca_columns)\n",
        "df_pca['Rf'] = y.values  # Reattach target column\n",
        "\n",
        "\n",
        "# Save to CSV\n",
        "df_pca.to_csv(\"pca_transformed_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "8O2jgSiI_LFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simply show the DataFrame\n",
        "df_pca.head()  # Show first 5 rows\n"
      ],
      "metadata": {
        "id": "iSZCBMFBfp4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "JbL7Niz6fo6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Prepare pairwise combinations of all PCs\n",
        "pc_columns = [col for col in df_pca.columns if col.startswith(\"PC\")]\n",
        "\n",
        "# Assume pc_columns = ['PC1', 'PC2', 'PC3', ..., 'PC6']\n",
        "pair_combinations = []\n",
        "\n",
        "for i in range(len(pc_columns)):\n",
        "    for j in range(i + 1, len(pc_columns)):\n",
        "        pair_combinations.append((pc_columns[i], pc_columns[j]))\n",
        "\n",
        "# Plot all pairwise combinations in a grid\n",
        "n = len(pc_columns)\n",
        "fig, axes = plt.subplots(nrows=n-1, ncols=n-1, figsize=(16, 16))\n",
        "plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "# Plot each subplot only in the lower triangle\n",
        "for i in range(n-1):\n",
        "    for j in range(i+1):\n",
        "        ax = axes[i, j]\n",
        "        sns.scatterplot(data=df_pca, x=pc_columns[j], y=pc_columns[i+1], hue='Rf',\n",
        "                        palette='coolwarm', s=10, ax=ax, legend=True)\n",
        "        ax.set_xlabel(pc_columns[j])\n",
        "        ax.set_ylabel(pc_columns[i+1])\n",
        "\n",
        "# Hide upper triangle subplots and unused axes\n",
        "for i in range(n-1):\n",
        "    for j in range(i+1, n-1):\n",
        "        axes[i, j].set_visible(False)\n",
        "\n",
        "plt.suptitle(\"Pairwise PCA Scatter Plots Colored by Rf\", fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y_MBZ8hcEU_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute PCA loadings (contributions of original features to PCs)\n",
        "loadings = pd.DataFrame(pca.components_.T, index=X.columns, columns=[f'PC{i+1}' for i in range(n)])\n",
        "\n",
        "# Get top 10 contributing features for each PC\n",
        "top_features_set = set()\n",
        "for pc in loadings.columns:\n",
        "    top_features = loadings[pc].abs().sort_values(ascending=False).head(10).index.tolist()\n",
        "    top_features_set.update(top_features)\n",
        "\n",
        "# Get features to drop (those not in top_features_set)\n",
        "features_to_drop = set(df.columns) - top_features_set - {'Rf'}\n",
        "\n",
        "# Create filtered DataFrame\n",
        "filtered_df = df.drop(columns=features_to_drop)\n",
        "filtered_df.to_csv('/content/gdrive/MyDrive/dataset_filtered_by_top_pca_loadings.csv', index=False)\n",
        "\n",
        "print(f\"Filtered dataset shape: {filtered_df.shape}\")\n",
        "# Plot top 10 contributors for all PCs with loading values labeled\n",
        "n_comps = loadings.shape[1]\n",
        "plt.figure(figsize=(14, 16))\n",
        "\n",
        "for i in range(n_comps):  # PC1 to PCn\n",
        "    pc_name = f'PC{i+1}'\n",
        "    top_features = loadings[pc_name].abs().sort_values(ascending=False).head(10)\n",
        "    top_features_names = top_features.index\n",
        "    top_values = loadings.loc[top_features_names, pc_name]\n",
        "\n",
        "    ax = plt.subplot(int(np.ceil(n_comps/2)), 2, i+1)\n",
        "    bars = ax.barh(top_features_names[::-1], top_values[::-1], color='skyblue')\n",
        "    ax.set_title(f\"Top 10 Feature Contributions to {pc_name}\")\n",
        "    ax.set_xlabel(\"Loading Value\")\n",
        "    ax.grid(True)\n",
        "\n",
        "    # Add text labels on the bars\n",
        "    for bar in bars:\n",
        "        value = bar.get_width()\n",
        "        ax.text(\n",
        "            value + 0.01 * (1 if value > 0 else -1),  # offset slightly\n",
        "            bar.get_y() + bar.get_height() / 2,\n",
        "            f\"{value:.4f}\",\n",
        "            va='center',\n",
        "            ha='left' if value > 0 else 'right',\n",
        "            fontsize=9,\n",
        "            color='black'\n",
        "        )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lcKIf8lAEyzf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}